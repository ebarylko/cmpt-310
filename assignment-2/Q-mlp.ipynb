{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Install and import the libraries"
      ],
      "metadata": {
        "id": "5uzCG0y3M1qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlxJY3TpK8Yz"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2tA99eQILKAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set Random Seed for Reproducibility"
      ],
      "metadata": {
        "id": "7CaOcisfLuyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "5oQH0zVbLMnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Preprocess the MNIST Dataset"
      ],
      "metadata": {
        "id": "ciTkMSe1L2ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train_orig), (x_test, y_test_orig) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the images to [0, 1] range and flatten them\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_train_flat = x_train.reshape(-1, 28 * 28)\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_test_flat = x_test.reshape(-1, 28 * 28)\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train_orig, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test_orig, num_classes)"
      ],
      "metadata": {
        "id": "WITuPqjqLO9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Hyperparameters"
      ],
      "metadata": {
        "id": "rTE0YgXBL7Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' TODO: Adjust the following parameters with different values. Save the plots and test results for each setup.\n",
        "    TODO: write a report about your findings from varying the parameters and their effect on overall performance. '''\n",
        "\n",
        "# lr: 0.1, 0.01, ...\n",
        "# epoch: 5, 10, 50, ...\n",
        "# layer: [128], [256, 256], ... .\n",
        "learning_rate = 0.01\n",
        "num_epochs = 5\n",
        "hidden_layers = [128]"
      ],
      "metadata": {
        "id": "AOgZZ0fPLRdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Define the Neural Network Model"
      ],
      "metadata": {
        "id": "olzhlK8lMGaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mlp_model(input_size, hidden_layers, output_size):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Input layer is defined by specifying input_shape in the first layer\n",
        "    for i, units in enumerate(hidden_layers):\n",
        "        if i == 0:\n",
        "            # First hidden layer with input shape specified\n",
        "            model.add(layers.Dense(units, activation='relu', input_shape=(input_size,)))\n",
        "        else:\n",
        "            # Subsequent hidden layers\n",
        "            model.add(layers.Dense(units, activation='relu'))\n",
        "\n",
        "    # Output layer with softmax activation for multi-class classification\n",
        "    model.add(layers.Dense(output_size, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_size = 28 * 28  # MNIST images are 28x28 pixels\n",
        "output_size = num_classes  # 10 classes for digits 0-9\n",
        "\n",
        "# Create the model\n",
        "model = create_mlp_model(input_size, hidden_layers, output_size)"
      ],
      "metadata": {
        "id": "gPDSOtNhLYjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Compile the Model"
      ],
      "metadata": {
        "id": "cKWa-rZnMQRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "hnd7zMKiLcGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train the Model"
      ],
      "metadata": {
        "id": "EarGwXN5MURa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train_flat, y_train,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.1,  # Use 10% of training data for validation\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "3mL9UjfQLeOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Evaluate the Model on Test Data"
      ],
      "metadata": {
        "id": "RrUVh4GPMX9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test_flat, y_test, verbose=0)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "P5rDgIgFLgig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Visualize Training History"
      ],
      "metadata": {
        "id": "6yzPT_XKMbaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7VsfWuk5Limu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Test the Model on Random Input Data"
      ],
      "metadata": {
        "id": "XG23TVq7MgDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select random samples from the test set\n",
        "num_samples = 5\n",
        "random_indices = np.random.choice(x_test.shape[0], num_samples, replace=False)\n",
        "random_images = x_test[random_indices]\n",
        "random_images_flat = x_test_flat[random_indices]\n",
        "random_labels = y_test_orig[random_indices]\n",
        "\n",
        "# Predict the labels of the random images\n",
        "predictions = model.predict(random_images_flat)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Plot the random images along with predicted and true labels\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1, num_samples, i+1)\n",
        "    plt.imshow(random_images[i], cmap='gray')\n",
        "    plt.title(f\"True: {random_labels[i]}\\nPredicted: {predicted_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Frgob4tOLlMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ZfjqxTrLnRC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}